I used ChatGPT-5 Thinking to solve the homework problems in part (3). I pasted the whole README.md file into the prompt 
and told it to follow the directions. The AI generally nailed it. However, in problem 1, I had to make some additions (I 
had to include "using hw2::fixed_point_iteration, using hw2::bisection; using hw2::newton_raphson;") at the top of the 
test_ai.cpp file to get it to compile correctly. More importantly, the AI did not want to implement regular fixed point 
iteration in part 1 of problem 2; instead, it introduced a damping factor for "simple adaptive damping." This is probably 
because regular fixed point iteration generally doesn't work very well, and because the AI lacked the context of what we 
had covered in class. In any case, the AI still neglected to follow the exact directions of the assignment. For problem 2, 
the AI's attempt compiled without issue and gave (presumably) correct answers, as they matched mine.

It is generally useful that AI can verify my own answers, and it is nice that, in a pinch, I know I can rely on AI
to help me code accurately at a much faster pace. However, using AI without understanding how to do the coding 
oneself generally leads to issues, since one ends up relying on AI completely and can't diagnose any coding bugs that arise
or modify the code themselves. Additionally, as we have seen here, it is annoying when the AI does not follow explicit 
directions on the first try, though that is not the biggest issue here, where it was attempting to implement a variant
of the method which performs better.